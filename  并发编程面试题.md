
# `什么线程安全？`
  线程安全本质是多个线程对共享资源进行操作，而且操作资源的代码有多句。cpu执行多线程时，在执行的过程中可能随时切换到其他的线程上执行。这样造成了运行结果和预期正常结果不一致，`准确说是如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。`


# # `1. JUC`
## #`你说你熟悉并发编程，那么你说说Java锁有哪些种类，以及区别`
相同点是阻塞式的锁，都能保证线程正确地被同步。   
**`Synchronized关键字`**   
保证了原子性和可见性。
是Java原生的语法，具体依赖的是JVM底层实现。通过查看字节码：代码块同步时用monitorenter和monitorexit来包裹同步代码实现的，修饰方式时，在编译的字节码中可以看到是直接在方法上标识Synchronize。    
Synchronize关键字用的锁就是存放在Java对象头中。java对象投分为两部分MarkWord(标记字符)、Class Point(类型指针)。而锁信息就存放在MarkWord中(Markword中有轻量级锁、重量级锁的标志位，重量级锁是会先操作重量级锁的标志位)。java在jdk1.6后做了优化，包括锁升级、锁清除(jvm扫描不存在锁竞争时)、锁膨胀、偏向锁。   
**`锁升级`**   
锁的4中状态：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态（级别从低到高）   
在没有锁竞争时，会先采用`偏向锁`，因为研究人员发现，大多时候不存在锁竞争，常常一个线程多次获得同一个锁。会在锁对象头和栈帧中记录偏向的锁的threadID，因为偏向锁不会主动释放锁，因此以后线程1再次获取锁的时候，需要比较当前线程的threadID和Java对象头中的threadID是否一致。    
`轻量级锁`考虑的是，如果竞争不多，获取锁的时间不长时，转变为重量级锁(转为内核态)前的自旋尝试。会先在当前线程创建一个锁记录(Lock Rcord)的空间，然后CAS把锁对象头的MarkWord拷贝到锁记录空间。成功后会尝试使用CAS让锁对象头的MarkWord执行这个锁记录空间，同时更改轻量级锁标志位。如果没有竞争的话会尝试自旋几次，如果自旋时有其他线程竞争则会升级为重量级锁，把所有未拥有锁的线程阻塞。 解锁过程就是把锁记录空间的替换回去。  
> Synchronized关键字和锁升级，详细分析偏向锁和轻量级锁的升级:https://blog.csdn.net/tongdanping/article/details/79647337  
> ☆啃碎并发（七）：深入分析Synchronized原理:https://www.jianshu.com/p/e62fa839aa41

**`重量级锁`**   
Synchronized是通过对象内部的一个叫做 监视器锁（Monitor）来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex(互斥量) Lock来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为 “重量级锁”。

**`ReentrantLock`**
是一个基于AQS的重入锁，支持公平锁(有序获取锁)和非公平锁(在进入等待对列时会先尝试竞争一下)。使用ReentrantLock的好处是更自由，因为要自己定义加锁和解锁，同时AQS底层是采用了CAS思想，不用切换到内核态，更轻量级一些，同时支持外部中断和设置等待时间。

## #`synchronized 的实现原理以及锁优化？ `
👆参见上面部分
https://www.cnblogs.com/ZoHy/p/11313155.html

## ##`synchronized 和 lock 有什么区别？` 
一个底层JVM实现，通过monitor，加锁解锁不需要自己去控制。一个AQS实现。Lock更轻量级一些，同时ReentrantLock支持公平锁。

## ##`Java 的信号量？ `
Semaphore：用来限制同时访问某特定资源的操作数量，它保存了一系列的许可（permits），每次调用acquire()都将消耗一个许可，每次调用release()都将归还一个许可。
底层是采用AQS，AQS中的`state`变量存放的是许可证数量。

## ##`CountDownLatch 和 CyclicBarrier 的用法，以及相互之间的差别?` 
CountDownLatch不能循环使用，同时CountDownLatch下一步行动的控制者是外部线程。而CyclicBarrier的下一步执行者是当前执行的线程。同时CyclicBarrier可以多次使用。  
**CountDownLatch**   
底层也是AQS实现，`stat`放的等待数量。  
**CyclicBarrier**
底层是使用重入锁。主要是为了使用`Condition`对列,当线程执行到栅栏处，直接往ConditionObject添加当前线程，当线程都到达了栅栏处，然后唤醒全部。

## ##`synchronized 在静态方法和普通方法的区别？ `
锁是当前类的class对象 ，进入同步代码前要获得当前类对象的锁,

锁是当前实例对象 ，进入同步代码前要获得当前实例的锁

## ##`怎么实现所有线程在等待某个事件的发生才会去执行？`
CountDownLatch或者CyclicBarrier。

## ##`CAS？CAS 有什么缺陷，如何解决？` 
CAS是比较替换，是乐观锁，一般有3个参数，v内存值，E预期值，N要替换的值，当V=E时，替换V为N。缺陷是ABA问题AtomicStampedReference，底层是通过版本号

```
Pair<T> {

        final T reference;

        final int stamp;
```

## ##`AQS` 
抽象队列同步器，全名：AbstractQueuedSynchronizer，是构建锁和同步器提供的一种基础框架。底层使用先进先出的FIFO等待队里来存放阻塞的线程。核心方法主要独占资源(acquire)和共享资源(share acquire)。核心属性还有一个int类型的stat变量，你可以自定此变量的意义。比如独占锁的重入功能，共享锁的获取资源数量。
当然可能单独 FIFO队列无法满足一些情况，比如闭锁。
**Sync Queue**
![avatar](https://s2.ax1x.com/2019/10/11/uqHnO0.jpg)   
**Condition Queue**
是Sync Queue的拓展，Condition的底层实现。
![avatar](https://s2.ax1x.com/2019/10/11/uqH4AS.jpg)


## ##`Condition 条件`
Condition类似于,wait()和notify,作用大致相同,不过wait和notify是个synchronized关键字合作使用的.而Condition是与重入锁相关联的。   
Condition在其他JDK源码中也广泛使用,比如ArrayBlockingQueue 中的put方法

## ##`ThreadLocal原理，用的时候需要注意什么？` 
在并发编程时会产生线程安全问题，一般都是多个线程同时操作统一资源，ThreadLocal的思想是，每个线程持有一份自己的引用，那么久不会产生问题。

THread类中有一个ThreadLocalMap ，类似于Hashap，ThreadLocal的get方法就是获取当前线程里的ThreadLocalMap。使用时要注意：使用完后要注意remove ThreadLocalMap，否则会造成内存溢出。

 Random底层使用   private final AtomicLong seed;来做随机种子，在多线程并发是，竞争激烈，性能并不好。

## ##`LockSupport工具 `
一个线程阻塞工具，可以让线程阻塞。   底层是UNSAFE.park(false, 0L);

## ##`Condition接口及其实现原理 `
Condition类似于,wait()和notify,作用大致相同,不过wait和notify是个synchronized关键字合作使用的.而Condition是与重入锁相关联的.主要有：await方法，是当前线程等待，同时释放锁。singal()唤醒等待中的线程。

## ##`Fork/Join框架的理解 `
todo

##  ##`分段锁的原理,锁力度减小的思考` 
JDK1.7中的ConcurrenHashMap采用分段锁的策略(即由多个Segment(段)组成的。每个Segment中都有着类似于数组加链表的结构)，好处是分散锁粒度。这样多线程并发时，不容易才生竞争。
至于ConcurrentHashMap放弃的原因大概有以下几点；
1. 加入多个分段锁浪费内存空间。
2. 生产环境中， map 在放入时竞争同一个锁的概率非常小，分段锁反而会造成更新(并不需要锁)等操作的长时间等待。     

**LongAdder**
LongAddr也是采用了此策略。传统Atomic采用CAS确实解决的并发原子性问题，但是在大量进程是，过多的CAS会导致性能的急剧下降，适得其反，这时候LongAddr出现了，采用将数据分段的机制保证了性能。
`为什么ConcurrentHashMap都放弃分段策略，LongAddr还要使用了？`因为LongAddr内部只有一个数，其他线程都是对这个数进行修改。而且LongAddr底层是一个数组，每个里面只是一个Long，对资源占用并不大。

## ##`伪共享(LongAdder中的@sun.misc.Contended引出)`
缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。如果在单线程情况中，缓存行 确实能提高性能，但是在多线程编程情况，a,b线程并发操作同一个数组中的不同数据时，当a线程操作完了刷新到主存，这时候b线程就会重新从主存读取缓存行数据，再进行操作，本来这次读取是不需要的，操作的不是同一个数据。造成了CPU系统资源的浪费。   
在LongAdder的父类Striped64就是用了@sun.misc.Contended来避免伪共享，原理是在使用此注解的对象或字段的前后各增加128字节大小的padding，使用2倍于大多数硬件缓存行的大小来避免相邻扇区预取导致的伪共享冲突。

## ##`ConcurrenHashMap 介绍？1.8 中为什么要用红黑树？` 
因为ConcurrenHashMap1.8中直接套用了HashMap的代码，同时使用synchronized 和CAS来保证线程安全。

## ##`如何检测死锁？怎么预防死锁？` 
检测死锁可以使用 jstack 查看 java 栈，如果出现死锁，那么内容最下方会出现 dealock标识。

预防死锁：主要是避免锁嵌套使用，同时锁使用完记得释放锁。

## ##`八种阻塞队列以及各个阻塞队列的特性`
todo

## ##`有哪些线程安全的List`
CopyOnWriteArrayList ：读写分离，写时复制出一个新的数组，完成插入、修改或者移除操作后将新数组赋值给array


## ## `CAS底层原理？(C++)`

# `2. JMM`
## ##`Java 内存模型？ `
java内存模型就是JMM，Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。是一个抽象的概念。 
java间的线程通信受jmm控制，jmm决定了一个共享变量的写入何时对另外一个线程可见。JMM定义了线程和主内存之间的抽象管理。同时JMM屏蔽了各个系统内存差异化。   
![avatar](https://s2.ax1x.com/2019/10/11/uLkz11.jpg)

**jmm下的多线程通信原理**   
![avatar](https://s2.ax1x.com/2019/10/11/uLAKnf.png)

## ##`如何保证多线程下 i++ 结果正确？ `
同步加锁

## ##`如何保证内存可见性`
volatile关键字。

##  ##`volatile 的实现原理？` 
volatile 主要是为了可见性和有序性(防止重排序)，可见性原理是缓存一致性。禁止重排序主要就是内存屏障。
volatile指令会在写操作编程成汇编时加入`lock`指令，每个CPU核心都有属于自己的缓存(一般是3级缓存，1、2CPU独占，3级个CPU共享)。根据缓存一致性协议，每个CPU核会进行总线嗅探，而lock指令在操作完成后(写回主内存)向总线发送`lock`消息，然后其他CPU嗅探到此消息会判断自己CPU缓存中的数据是否已过期，过期了则会废弃掉缓存重新从主内存读取。

## ## `上问题的一点拓展`
主`内存、工作内存和Java内存区域中的堆、栈、方法区等并不是一个层次的划分，两者基本没有关系。`
如果`勉强关联类比下`的话：`主内存主要对应的Java堆中的对象实例数据部分，而工作内存则对应虚拟机栈中的部分区域。更低层次上说：主内存就直接对应物理硬件的内存，而为了获取更好的速度，虚拟级(甚至是硬件系统本身的优化措施)可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要读写的是工作内存。`

## ## `final的内存语义(很少问，当个拓展吧)`
`final`保证在对象引用线程可见之前，对象的final域肯定会被正确初始化了。
在对象引用编程线程可见之前，对象的final域肯定会被正确初始化了,而普通域不会有这个保证。 
注： 如果构造对象发生了溢出，则不能保证。     
```
   static FinalExample finalExample;
    public FinalExample() {
        this.i = 666;
        // 这就是溢出，外部可以访问 未初始化完成的对象
        finalExample = this;
        this.he = "SSSSSB";
    }
```
实现的原理为：
- JMM禁止编译器吧final域的写重排序到构造函数外
- 编译器会在 final域写之后，构造函数 return 之前，插入一个内存屏障(StoreStore屏障)。      

**读final域**    
编译器会在读 final域 操作前插入一个LoadLoad屏障


##  ##`happen-before原则` 
重排序规则，定义了那些不会被重排。
happens-before原则概览
1. 程序顺序原则：一个线程内包证语义的串行性。串行性，我个人感觉主要就是两条语句2. 如果存在依赖关系，那么不会发生重排。as-if-serial的封装
2. volatile规则：volatile变量的写，先发生于读，这保证了volatile变量的可见性。
3. 传递性：解锁必须发生在加锁前。
4. 传递性：A先于B，B先于C，那么A必然先于C
5. 线程的start()方法先于它的每一个动作。
6. 线程的所有操作先于线程的终结(Thread.join())
7. 线程的中断(interrupt)先于被中断线程的代码。
8. 线程的构造函数执行、结束优先于finalize()方法。 
9.  一个happens-before规则对应一个或多个编译器和处理器重排序规则。

## ## `传统懒汉模式多线程存在的问题？`
```
 private static Singleton2 instance;
    public static synchronized Singleton2 getInstance(){
        if(instance == null) {
            synchronized (Singleton2.class){
                if (instance == null){
                    instance = new Singleton2();
                }
            }
        }
        return instance;
    }
```
传统双重检查锁是会存在问题的，因为`synchronized`代码块内部可能发生重排序，实例化一个对象有3步：
1. 开辟空间
2. 使用开辟的空间初始化对象
3. 是实例引用指向分配的内存空间。

2、3没有依赖，可能存在重排序问题，这时候线程B执行`if(instance  ==  null)` 就是为false，但是对象并没有初始完成，这时候线程B执行业务逻辑就会产生错误的结果。
`解决方案是在单例对象使用volatile修饰，保证不会发生重排序。`

# `3. 线程池`
##  ## `创建线程的几种方式？`
1. 继承Thread 
好处是直接可以使用this。不用使用Thread.currentThread()方法获取当前线程。同时也方便传参
2. 实现Runable接口
3. 使用FutureTask方式 

## ##`线程池的种类，区别和使用场景？` 
Executor
为什么使用线程池，使用线程池适用于频繁创建、销毁线程的场景，创建线程其实很消耗资源，这时候可以服用线程资源，所以有了线程池。
1. 固定线程池(newFixedThreadPool)：线程池中的线程数量不变。任务队里采用LinkedBlockingQueue，无界队列。
2. 只有一个线程的线程池(newSingleThreadExecutor)。多余任务会保存到任务队列中。
3. 延时线程池（newScheduledThreadPool)

不过很少直接使用Executor来创建线程池，因为固定线程池的缓存对列时一个无界对列，可能会有oom的情况。一般都是直接使用`ThreadPoolExecutor`自定义创建。

## ##`分析线程池的实现原理和线程的调度过程？` 
Executors底层是使用ThreadPoolExecutor类，他有5个参数，核心线程数量、最大线程数量、线程池超过核心线程数后的多余线程存活时间、任务队列、线程工厂(用于创建线程)、拒绝策略。

`调度策略`：先判断当前执行任务数量是否大于核心线程数，如果小于直接执行，大于则提交到任务队里，如果任务队列满了，则创建线程到最大线程数，如果大于最大线程数，则执行拒绝策略。

## ##`线程池拒绝策略有几种`
有4中拒绝策略
1. AbortPolicy(默认)：会直接抛出异常。
2. CallerRunsPolicy：直接在调用线程中运行此任务，不会丢失，但是造成性能下降。
3. DiscardPolicy：丢弃当前无法加入的任务。
4. DiscardOldestPolicy：丢失最老的任务，也就是即将执行的任务。

## ##`线程池如何调优，最大数目如何确认？` 
线程池最好自己手动ThreadPoolExecutor，这样可空性更强。

很多时候最简单 粗暴的是: 
- 如果是IO密集型应用，则线程池大小设置为2N+1； 
- 如果是CPU密集型应用，则线程池大小设置为N+1；

## ##`线程池的状态有几种？`
 在ThreadPoolExecutor中，其类变量ctl的高三位代表线程池状态：
- RUNNING：运行状态，正常工作
- SHUTDOWN：关闭状态，不接受新任务，但会处理在阻塞队列中排队的队伍
- STOP：停止状态，不接受新任务，也不处理排队的任务，同时会中断执行中的任务
- TIDYING：整理状态，所有任务终止，没有工作线程，即将运行terminated方法来终结线程池
- TERMINATED：终结状态，terminated方法结束后线程池终结

状态的转换通过以下方式：
![avatar](https://s2.ax1x.com/2019/10/11/uqeV0K.jpg)

## ## `一个线程池中的线程异常了，那么线程池会怎么处理这个线程?`
> https://www.jianshu.com/p/40e8f4ccc796

- 当执行方式是execute时,可以看到堆栈异常的输出。
- 当执行方式是submit时,堆栈异常没有输出。但是调用Future.get()方法时，可以捕获到异常。

不会影响线程池里面其他线程的正常执行。线程池会把这个线程移除掉，并创建一个新的线程放到线程池中。

# #`4. 其他`
# `wait和sleep的区别` 
wait需要配合synchronized使用，作用是停顿且释放锁。
sleep是睡眠，不会释放锁。

## ##`Hashtable 是怎么加锁的 ？` 
直接用synchronized包裹

##  ##`HashMap 的并发问题？` 
集合类，但是在多线程情况下会有并发安全问题，主要是Rehash时会出现问题，当HashMap容量达到负载因子是就会扩容，扩容简单说有两步

1. 创建一个新的Entry空数组，长度是原数组的2部。

2. ReHash：变量原数组，然后把所有Entry重新Hash到新数组。

在并发情况下会造成循环链表，死循环。

https://blog.csdn.net/bjwfm2011/article/details/81076736

## ##`线程java进程占用cpu 100%`
1. 使用命令top -p <pid> ，显示你的java进程的内存情况，pid是你的java进程号，比如123
2. 按H，获取每个线程的内存情况
3. 找到内存和cpu占用最高的线程pid，比如15248
4. 执行 printf 0x%x 15248 得到 0x3b90 ,此为线程id的十六进制
5. 执行 jstack 123|grep -A 10 3b90，得到线程堆栈信息中3b90这个线程所在行的后面10行
6. 查看对应的堆栈信息找出可能存在问题的代码